# TaxoConserv Test Datasets

This directory contains various test datasets for testing TaxoConserv functionality with different data sizes and scenarios.

## 📊 Dataset Overview

### Standard Test Files
- **`test_data.csv`** - Basic test dataset (small, ~200 rows)
  - Perfect for quick testing and development
  - Contains realistic phyloP, GERP, phastCons scores
  - Multiple taxonomic groups (Primates, Carnivores, Birds, etc.)

- **`test_file.csv`** - Alternative small test dataset
  - Similar structure to test_data.csv
  - Different data patterns for validation

### Performance Test Files
- **`taxoconserv_medium_test.csv`** - Medium dataset (~10,000 rows)
  - Tests medium-scale performance
  - Multiple conservation scores
  - Good for testing optimization features

- **`taxoconserv_large_test.csv`** - Large dataset (~50,000 rows)
  - Tests large-scale performance
  - Triggers performance optimizations
  - Tests data sampling features

- **`taxoconserv_xlarge_test.csv`** - Extra large dataset (~100,000+ rows)
  - Stress testing for very large datasets
  - Tests memory management
  - Validates performance warnings and optimizations

- **`taxoconserv_large_dataset.csv`** - Production-scale dataset
  - Real-world scale testing
  - Complex taxonomic hierarchies
  - Multiple conservation score types

### Edge Case Test Files
- **`empty_test.csv`** - Empty dataset
  - Tests error handling for empty files
  - Validates graceful failure modes

- **`invalid_test.csv`** - Invalid/corrupted dataset
  - Tests error handling for malformed data
  - Validates data validation routines

## 🧪 Usage Examples

### CLI Testing
```bash
# Test with small dataset
python taxoconserv.py -i test_datasets/test_data.csv -o results/

# Test with large dataset
python taxoconserv.py -i test_datasets/taxoconserv_large_test.csv -o results/ --verbose

# Test interactive mode
python taxoconserv.py -i test_datasets/taxoconserv_medium_test.csv -o results/ --interactive
```

### Web Interface Testing
```bash
# Start web interface
streamlit run web_taxoconserv.py

# Upload any of the test files via the web interface
# Large files will trigger performance optimizations
```

### Python API Testing
```python
import pandas as pd
from src.analysis import perform_statistical_analysis

# Load test data
df = pd.read_csv('test_datasets/test_data.csv')

# Run analysis
results = perform_statistical_analysis(df, 'phyloP_score', 'taxon_group')
```

## 📈 Performance Expectations

| Dataset | Size | Expected Load Time | Visualization Time | Memory Usage |
|---------|------|--------------------|--------------------|--------------|
| test_data.csv | ~200 rows | <1s | <2s | ~10MB |
| medium_test.csv | ~10K rows | ~2s | ~3s | ~50MB |
| large_test.csv | ~50K rows | ~5s | ~8s (with sampling) | ~200MB |
| xlarge_test.csv | ~100K+ rows | ~10s | ~5s (optimized) | ~500MB |

## 🔧 Data Format

All test datasets follow the standard TaxoConserv format:

**Required Columns:**
- `taxon_group` - Taxonomic grouping (categorical)
- Conservation scores (numeric) - at least one of:
  - `phyloP_score`
  - `GERP_score`
  - `phastCons_score`
  - `CADD_score`
  - `REVEL_score`

**Optional Columns:**
- `gene` - Gene identifier
- `chromosome` - Chromosome information
- `position` - Genomic position
- `family`, `genus`, `species` - Hierarchical taxonomy

## 🎯 Testing Scenarios

### Performance Testing
1. **Load Time**: Test file loading and parsing
2. **Analysis Speed**: Statistical analysis performance
3. **Visualization**: Plot generation speed
4. **Memory Usage**: Memory efficiency with large datasets

### Feature Testing
1. **Data Quality**: Missing values, outliers, small groups
2. **Multi-Score**: Multiple conservation scores
3. **Interactive**: Web interface functionality
4. **Export**: Data and plot export features

### Error Handling
1. **Empty Files**: Graceful handling of empty datasets
2. **Invalid Data**: Malformed or corrupted files
3. **Missing Columns**: Required column validation
4. **Edge Cases**: Single group, all missing values, etc.

## 📝 Notes

- Test datasets are synthetically generated but follow realistic patterns
- Large datasets may take time to load on slower systems
- Performance optimizations automatically activate for datasets >10K rows
- All test data is for research/educational purposes only

---

**Generated by TaxoConserv v2.0.0**  
*For more information, see the main [README.md](../README.md)*
